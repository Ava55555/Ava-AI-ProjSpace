{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Using the model\n",
    "\n",
    "Monitor real-time inference in action with a question-answering NLP task.\n",
    "\n",
    "**[4.1 Inference API Overview](#4.2-Inference-API-Overview)**<br>\n",
    "**[4.2 Preparing the Request](#4.3-Preparing-the-Request)**<br>\n",
    "**[4.3 Querying the Server](#4.4-Querying-the-Server)**<br>\n",
    "**[4.4 Post-Processing the Response](#4.5-Post-Processing-the-Response)**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import tritonclient.http"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to initialize the client by pointing it towards our server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    triton_client = tritonclient.http.InferenceServerClient(url=\"triton:8000\", verbose=True)\n",
    "except Exception as e:\n",
    "    print(\"channel creation failed: \" + str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, inspect the status of our server, and availability and status of our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET /v2/health/live, headers {}\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-length': '0', 'content-type': 'text/plain'}>\n",
      "True\n",
      "GET /v2/health/ready, headers {}\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-length': '0', 'content-type': 'text/plain'}>\n",
      "True\n",
      "GET /v2/models/bertQA-torchscript/versions/1/ready, headers {}\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-length': '0', 'content-type': 'text/plain'}>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "modelName = \"bertQA-torchscript\"\n",
    "print(triton_client.is_server_live())\n",
    "print(triton_client.is_server_ready())\n",
    "print(triton_client.is_model_ready(modelName,\"1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, inspect the metadata returned by the server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET /v2, headers {}\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-type': 'application/json', 'content-length': '285'}>\n",
      "bytearray(b'{\"name\":\"triton\",\"version\":\"2.34.0\",\"extensions\":[\"classification\",\"sequence\",\"model_repository\",\"model_repository(unload_dependents)\",\"schedule_policy\",\"model_configuration\",\"system_shared_memory\",\"cuda_shared_memory\",\"binary_tensor_data\",\"parameters\",\"statistics\",\"trace\",\"logging\"]}')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'triton',\n",
       " 'version': '2.34.0',\n",
       " 'extensions': ['classification',\n",
       "  'sequence',\n",
       "  'model_repository',\n",
       "  'model_repository(unload_dependents)',\n",
       "  'schedule_policy',\n",
       "  'model_configuration',\n",
       "  'system_shared_memory',\n",
       "  'cuda_shared_memory',\n",
       "  'binary_tensor_data',\n",
       "  'parameters',\n",
       "  'statistics',\n",
       "  'trace',\n",
       "  'logging']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triton_client.get_server_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Inference API Overview\n",
    "\n",
    "Since we have been working with a neural network built to do question answering, we'll run an example query against our server. To start, let's investigate the shape of the input and output data that the server will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GET /v2/models/bertQA-torchscript, headers {}\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-type': 'application/json', 'content-length': '379'}>\n",
      "bytearray(b'{\"name\":\"bertQA-torchscript\",\"versions\":[\"1\"],\"platform\":\"pytorch_libtorch\",\"inputs\":[{\"name\":\"input__0\",\"datatype\":\"INT64\",\"shape\":[-1,384]},{\"name\":\"input__1\",\"datatype\":\"INT64\",\"shape\":[-1,384]},{\"name\":\"input__2\",\"datatype\":\"INT64\",\"shape\":[-1,384]}],\"outputs\":[{\"name\":\"output__0\",\"datatype\":\"FP32\",\"shape\":[-1,384]},{\"name\":\"output__1\",\"datatype\":\"FP32\",\"shape\":[-1,384]}]}')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'bertQA-torchscript',\n",
       " 'versions': ['1'],\n",
       " 'platform': 'pytorch_libtorch',\n",
       " 'inputs': [{'name': 'input__0', 'datatype': 'INT64', 'shape': [-1, 384]},\n",
       "  {'name': 'input__1', 'datatype': 'INT64', 'shape': [-1, 384]},\n",
       "  {'name': 'input__2', 'datatype': 'INT64', 'shape': [-1, 384]}],\n",
       " 'outputs': [{'name': 'output__0', 'datatype': 'FP32', 'shape': [-1, 384]},\n",
       "  {'name': 'output__1', 'datatype': 'FP32', 'shape': [-1, 384]}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triton_client.get_model_metadata(modelName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have recieved a response similar to the below: <br/>\n",
    "<img width=1000 src=\"images/DataFormat.png\"/>\n",
    "\n",
    "The server indicated that it expects three input tensors:\n",
    "- input__0 being the input_ids\n",
    "- input__1 being the sequence_ids\n",
    "- input__2 being the mask_ids\n",
    "\n",
    "The server will respond with:\n",
    "- output__0 being the start logits\n",
    "- output__1 being the end logits\n",
    "\n",
    "We now need to pre process our question and context into the format required by the server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Preparing the Request\n",
    "\n",
    "Start by creating the question and an answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Most antibiotics target bacteria and don't affect what class of organisms? \"\n",
    "context = \"Within the genitourinary and gastrointestinal tracts, commensal flora serve as biological barriers by \" +\\\n",
    "        \"competing with pathogenic bacteria for food and space and, in some cases, by changing the conditions in \" +\\\n",
    "        \"their environment, such as pH or available iron. This reduces the probability that pathogens will \" +\\\n",
    "        \"reach sufficient numbers to cause illness. However, since most antibiotics non-specifically target bacteria\" +\\\n",
    "        \"and do not affect fungi, oral antibiotics can lead to an overgrowth of fungi and cause conditions such as a\" +\\\n",
    "        \"vaginal candidiasis (a yeast infection). There is good evidence that re-introduction of probiotic flora, such \" +\\\n",
    "        \"as pure cultures of the lactobacilli normally found in unpasteurized yogurt, helps restore a healthy balance of\" +\\\n",
    "        \"microbial populations in intestinal infections in children and encouraging preliminary data in studies on bacterial \" +\\\n",
    "        \"gastroenteritis, inflammatory bowel diseases, urinary tract infection and post-surgical infections. \" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, by importing some additional utilities that will hide the boilerplate logic necessary for data transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/dli/task/client')\n",
    "from tokenization import BertTokenizer\n",
    "from inference import preprocess_tokenized_text,parse_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of code transforms the data into the required format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer(\"/dli/task/vocab\", do_lower_case=True, max_len=512) \n",
    "doc_tokens = context.split()\n",
    "query_tokens = tokenizer.tokenize(question)\n",
    "\n",
    "tensors_for_inference, tokens_for_postprocessing = preprocess_tokenized_text(doc_tokens, \n",
    "                                    query_tokens, \n",
    "                                    tokenizer, \n",
    "                                    max_seq_length=384, \n",
    "                                    max_query_length=64)\n",
    "\n",
    "dtype = np.int64\n",
    "input_ids = np.array(tensors_for_inference.input_ids, dtype=dtype)[None,...] # make bs=1\n",
    "segment_ids = np.array(tensors_for_inference.segment_ids, dtype=dtype)[None,...] # make bs=1\n",
    "input_mask = np.array(tensors_for_inference.input_mask, dtype=dtype)[None,...] # make bs=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we copy the data into the structures required by Triton. Do notice that we use tensor names, data types and tensor dimensions as specified by the Triton server response earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "inputs.append(tritonclient.http.InferInput('input__0', [1, len(input_ids[0])], \"INT64\"))\n",
    "inputs.append(tritonclient.http.InferInput('input__1', [1, len(segment_ids[0])], \"INT64\"))\n",
    "inputs.append(tritonclient.http.InferInput('input__2', [1, len(input_mask[0])], \"INT64\"))\n",
    "\n",
    "\n",
    "inputs[0].set_data_from_numpy(input_ids, binary_data=False)\n",
    "inputs[1].set_data_from_numpy(segment_ids, binary_data=False)\n",
    "inputs[2].set_data_from_numpy(input_mask, binary_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting one of the inputs reveals the new data representation, which was tokenized and converted to the numerical format as required by the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'input__0',\n",
       " 'shape': [1, 384],\n",
       " 'datatype': 'INT64',\n",
       " 'data': [101,\n",
       "  2087,\n",
       "  24479,\n",
       "  4539,\n",
       "  10327,\n",
       "  1998,\n",
       "  2123,\n",
       "  1005,\n",
       "  1056,\n",
       "  7461,\n",
       "  2054,\n",
       "  2465,\n",
       "  1997,\n",
       "  11767,\n",
       "  1029,\n",
       "  102,\n",
       "  2306,\n",
       "  1996,\n",
       "  8991,\n",
       "  9956,\n",
       "  9496,\n",
       "  24041,\n",
       "  1998,\n",
       "  3806,\n",
       "  13181,\n",
       "  18447,\n",
       "  19126,\n",
       "  22069,\n",
       "  1010,\n",
       "  4012,\n",
       "  3549,\n",
       "  12002,\n",
       "  10088,\n",
       "  3710,\n",
       "  2004,\n",
       "  6897,\n",
       "  13500,\n",
       "  2011,\n",
       "  6637,\n",
       "  2007,\n",
       "  26835,\n",
       "  2594,\n",
       "  10327,\n",
       "  2005,\n",
       "  2833,\n",
       "  1998,\n",
       "  2686,\n",
       "  1998,\n",
       "  1010,\n",
       "  1999,\n",
       "  2070,\n",
       "  3572,\n",
       "  1010,\n",
       "  2011,\n",
       "  5278,\n",
       "  1996,\n",
       "  3785,\n",
       "  1999,\n",
       "  2037,\n",
       "  4044,\n",
       "  1010,\n",
       "  2107,\n",
       "  2004,\n",
       "  6887,\n",
       "  2030,\n",
       "  2800,\n",
       "  3707,\n",
       "  1012,\n",
       "  2023,\n",
       "  13416,\n",
       "  1996,\n",
       "  9723,\n",
       "  2008,\n",
       "  26835,\n",
       "  2015,\n",
       "  2097,\n",
       "  3362,\n",
       "  7182,\n",
       "  3616,\n",
       "  2000,\n",
       "  3426,\n",
       "  7355,\n",
       "  1012,\n",
       "  2174,\n",
       "  1010,\n",
       "  2144,\n",
       "  2087,\n",
       "  24479,\n",
       "  2512,\n",
       "  1011,\n",
       "  4919,\n",
       "  4539,\n",
       "  10327,\n",
       "  5685,\n",
       "  2079,\n",
       "  2025,\n",
       "  7461,\n",
       "  15289,\n",
       "  1010,\n",
       "  8700,\n",
       "  24479,\n",
       "  2064,\n",
       "  2599,\n",
       "  2000,\n",
       "  2019,\n",
       "  2058,\n",
       "  26982,\n",
       "  1997,\n",
       "  15289,\n",
       "  1998,\n",
       "  3426,\n",
       "  3785,\n",
       "  2107,\n",
       "  2004,\n",
       "  10927,\n",
       "  24965,\n",
       "  27467,\n",
       "  9032,\n",
       "  6190,\n",
       "  1006,\n",
       "  1037,\n",
       "  21957,\n",
       "  8985,\n",
       "  1007,\n",
       "  1012,\n",
       "  2045,\n",
       "  2003,\n",
       "  2204,\n",
       "  3350,\n",
       "  2008,\n",
       "  2128,\n",
       "  1011,\n",
       "  4955,\n",
       "  1997,\n",
       "  4013,\n",
       "  26591,\n",
       "  10088,\n",
       "  1010,\n",
       "  2107,\n",
       "  2004,\n",
       "  5760,\n",
       "  8578,\n",
       "  1997,\n",
       "  1996,\n",
       "  18749,\n",
       "  3406,\n",
       "  3676,\n",
       "  6895,\n",
       "  6894,\n",
       "  5373,\n",
       "  2179,\n",
       "  1999,\n",
       "  4895,\n",
       "  19707,\n",
       "  2618,\n",
       "  28405,\n",
       "  10930,\n",
       "  27390,\n",
       "  2102,\n",
       "  1010,\n",
       "  7126,\n",
       "  9239,\n",
       "  1037,\n",
       "  7965,\n",
       "  5703,\n",
       "  1997,\n",
       "  7712,\n",
       "  3217,\n",
       "  21102,\n",
       "  7080,\n",
       "  1999,\n",
       "  20014,\n",
       "  19126,\n",
       "  15245,\n",
       "  1999,\n",
       "  2336,\n",
       "  1998,\n",
       "  11434,\n",
       "  8824,\n",
       "  2951,\n",
       "  1999,\n",
       "  2913,\n",
       "  2006,\n",
       "  17341,\n",
       "  3806,\n",
       "  13181,\n",
       "  29110,\n",
       "  13706,\n",
       "  1010,\n",
       "  20187,\n",
       "  6812,\n",
       "  2884,\n",
       "  7870,\n",
       "  1010,\n",
       "  24471,\n",
       "  3981,\n",
       "  2854,\n",
       "  12859,\n",
       "  8985,\n",
       "  1998,\n",
       "  2695,\n",
       "  1011,\n",
       "  11707,\n",
       "  15245,\n",
       "  1012,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0]._get_tensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though it is possible to just fetch all of the output tensors associated with the request it is a good practice to fetch only the bare minimum to minimize the bandwidth. We do that by specifying the request output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "outputs.append(\n",
    "        tritonclient.http.InferRequestedOutput('output__0', binary_data=False))\n",
    "outputs.append(\n",
    "        tritonclient.http.InferRequestedOutput('output__1', binary_data=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 Querying the Server\n",
    "\n",
    "Let us now issue a request to the server. The <code>outputs</code> parameter is optional. If not specified all tensors will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST /v2/models/bertQA-torchscript/infer, headers {}\n",
      "{\"inputs\":[{\"name\":\"input__0\",\"shape\":[1,384],\"datatype\":\"INT64\",\"data\":[101,2087,24479,4539,10327,1998,2123,1005,1056,7461,2054,2465,1997,11767,1029,102,2306,1996,8991,9956,9496,24041,1998,3806,13181,18447,19126,22069,1010,4012,3549,12002,10088,3710,2004,6897,13500,2011,6637,2007,26835,2594,10327,2005,2833,1998,2686,1998,1010,1999,2070,3572,1010,2011,5278,1996,3785,1999,2037,4044,1010,2107,2004,6887,2030,2800,3707,1012,2023,13416,1996,9723,2008,26835,2015,2097,3362,7182,3616,2000,3426,7355,1012,2174,1010,2144,2087,24479,2512,1011,4919,4539,10327,5685,2079,2025,7461,15289,1010,8700,24479,2064,2599,2000,2019,2058,26982,1997,15289,1998,3426,3785,2107,2004,10927,24965,27467,9032,6190,1006,1037,21957,8985,1007,1012,2045,2003,2204,3350,2008,2128,1011,4955,1997,4013,26591,10088,1010,2107,2004,5760,8578,1997,1996,18749,3406,3676,6895,6894,5373,2179,1999,4895,19707,2618,28405,10930,27390,2102,1010,7126,9239,1037,7965,5703,1997,7712,3217,21102,7080,1999,20014,19126,15245,1999,2336,1998,11434,8824,2951,1999,2913,2006,17341,3806,13181,29110,13706,1010,20187,6812,2884,7870,1010,24471,3981,2854,12859,8985,1998,2695,1011,11707,15245,1012,102,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]},{\"name\":\"input__1\",\"shape\":[1,384],\"datatype\":\"INT64\",\"data\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]},{\"name\":\"input__2\",\"shape\":[1,384],\"datatype\":\"INT64\",\"data\":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]}],\"outputs\":[{\"name\":\"output__0\",\"parameters\":{\"binary_data\":false}},{\"name\":\"output__1\",\"parameters\":{\"binary_data\":false}}]}\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-type': 'application/json', 'content-length': '14796'}>\n",
      "bytearray(b'{\"model_name\":\"bertQA-torchscript\",\"model_version\":\"1\",\"outputs\":[{\"name\":\"output__0\",\"datatype\":\"FP32\",\"shape\":[1,384],\"data\":[-6.230499267578125,-5.988883972167969,-6.157662868499756,-6.068220138549805,-4.511059761047363,-6.177155494689941,-5.967012405395508,-6.233504772186279,-5.894256114959717,-5.607016563415527,-6.033555030822754,-6.302066802978516,-6.1433820724487309,-6.211335182189941,-6.353229522705078,-6.214388847351074,-6.006484508514404,-6.230810165405273,-5.773906230926514,-6.385979175567627,-6.442008972167969,-6.51027250289917,-6.268528938293457,-5.8167619705200199,-6.2957682609558109,-6.293145179748535,-6.492143630981445,-6.316490650177002,-6.441684246063232,-5.2130537033081059,-6.26846981048584,-6.562448024749756,-6.120388031005859,-6.368938446044922,-6.228872776031494,-6.038941383361816,-5.9520263671875,-6.278861999511719,-5.933716773986816,-6.097394943237305,-0.4255836009979248,-4.250476837158203,-1.1577064990997315,-6.150885581970215,-5.986797332763672,-6.278443336486816,-6.035305023193359,-6.371572971343994,-6.25974178314209,-6.109336853027344,-6.069693088531494,-6.317009449005127,-6.376258850097656,-6.140276908874512,-5.981710910797119,-6.3125739097595219,-6.21495246887207,-6.257209777832031,-6.214005470275879,-6.079260349273682,-6.480047225952148,-6.174410343170166,-6.160393238067627,-5.910329818725586,-6.313645362854004,-6.006374359130859,-5.042710304260254,-4.897219657897949,-5.9366350173950199,-5.893670082092285,-6.29451847076416,-6.10857629776001,-6.223854064941406,-4.444372177124023,-6.541983127593994,-6.334278106689453,-6.204667091369629,-6.230681419372559,-6.329833030700684,-6.143680572509766,-6.029391288757324,-5.858161926269531,-4.880578517913818,-5.457036972045898,-6.020756721496582,-3.5956075191497804,-4.555999755859375,-4.842551231384277,-3.9051060676574709,-6.273028373718262,-5.741571426391602,-5.56413459777832,-1.4180324077606202,-5.505593299865723,-3.1139514446258547,-3.674989700317383,-2.5593624114990236,6.444554328918457,-5.919814586639404,-4.818530559539795,-6.046281337738037,-6.152840614318848,-6.08233642578125,-6.016434669494629,-5.942195892333984,-5.502044200897217,-6.303074359893799,-5.619113445281982,2.059746265411377,-6.209651470184326,-5.982873916625977,-6.183112621307373,-6.164690017700195,-6.071428298950195,-5.423206329345703,-6.297128200531006,-5.7436842918396,-6.275795936584473,-6.381993770599365,-6.086480140686035,-5.758056640625,1.3109349012374879,-6.274995803833008,-6.462141036987305,-4.91004753112793,-6.046237468719482,-6.352934837341309,-6.024993419647217,-6.076229095458984,-6.187277793884277,-5.765937805175781,-6.218320369720459,-6.045365810394287,-6.1169891357421879,-3.0214786529541017,-5.87378454208374,-5.859982490539551,-6.384911060333252,-6.09990930557251,-6.125890254974365,-5.774184226989746,-6.0462775230407719,-6.209689617156982,-5.997866630554199,-4.082450866699219,-5.871559143066406,-6.062482833862305,-6.079421043395996,-5.932039737701416,-6.319857120513916,-6.283562660217285,-6.196689605712891,-5.967202186584473,-6.182669639587402,-6.131424903869629,-6.271121025085449,-5.920626640319824,-6.183327674865723,-6.240175724029541,-6.321979999542236,-6.001893043518066,-5.992398262023926,-6.084759712219238,-5.950427055358887,-5.876702785491943,-5.943562030792236,-1.6358087062835694,-3.792090892791748,-5.689518928527832,-5.912923336029053,-6.175482273101807,-5.813611030578613,-6.265515327453613,-6.098992824554443,-6.2200188636779789,-5.872401714324951,-6.246857643127441,-6.034208297729492,-5.954373359680176,-6.104467391967773,-6.19719123840332,-6.022829055786133,-6.145918846130371,-4.241030216217041,-5.627233505249023,-6.227786064147949,-6.188077926635742,-6.31075382232666,-6.299677848815918,-5.4718780517578129,-5.906654357910156,-6.216002941131592,-6.23799991607666,-6.272071838378906,-5.522697448730469,-6.189575672149658,-6.363315582275391,-6.272884368896484,-6.196014404296875,-6.173709869384766,-5.788290023803711,-6.176261901855469,-5.979022026062012,-6.1452813148498539,-4.981307029724121,-6.202968597412109,-6.322919845581055,-6.329955101013184,-6.325448513031006,-6.343123912811279,-6.335781574249268,-6.325469493865967,-6.341623306274414,-6.347020149230957,-6.3418869972229,-6.344242095947266,-6.351983070373535,-6.33751916885376,-6.335816383361816,-6.33724308013916,-6.329117774963379,-6.332694053649902,-6.335175037384033,-6.3353447914123539,-6.331275939941406,-6.341033458709717,-6.328495979309082,-6.330921649932861,-6.332862377166748,-6.336246490478516,-6.3307414054870609,-6.330048561096191,-6.334563255310059,-6.333468914031982,-6.324225425720215,-6.333013534545898,-6.339870929718018,-6.335681915283203,-6.244842529296875,-6.31939697265625,-6.313584804534912,-6.315464019775391,-6.320157527923584,-6.317197322845459,-6.317914009094238,-6.3297929763793949,-6.320620059967041,-6.322803020477295,-6.335894584655762,-6.330827236175537,-6.334707260131836,-6.328767776489258,-6.322883605957031,-6.321065902709961,-6.321737289428711,-6.320123195648193,-6.317036151885986,-6.321138381958008,-6.329167366027832,-6.324417591094971,-6.332271575927734,-6.328004837036133,-6.327323913574219,-6.325932502746582,-6.3245439529418949,-6.3319220542907719,-6.327070713043213,-6.32315731048584,-6.332600116729736,-6.3321380615234379,-6.3089599609375,-6.318873882293701,-6.321486949920654,-6.322027206420898,-6.323427200317383,-6.335472106933594,-6.341618061065674,-6.329572677612305,-6.338120937347412,-6.321803092956543,-6.323139190673828,-6.321608066558838,-6.323333740234375,-6.3245086669921879,-6.319706916809082,-6.316709518432617,-6.320237636566162,-6.323599815368652,-6.319183349609375,-6.327597618103027,-6.324700355529785,-6.326727867126465,-6.334610939025879,-6.327220439910889,-6.334694862365723,-6.33331823348999,-6.339317321777344,-6.333971977233887,-6.340062618255615,-6.332002639770508,-6.336420059204102,-6.340599536895752,-6.349415302276611,-6.345625877380371,-6.341984748840332,-6.3473711013793949,-6.3391947746276859,-6.346607208251953,-6.3457136154174809,-6.341335296630859,-6.347115516662598,-6.334847450256348,-6.341502666473389,-6.322150707244873,-6.327180862426758,-6.305464744567871,-6.318155765533447,-6.317934989929199,-6.312572479248047,-6.31016731262207,-6.3075103759765629,-6.335877895355225,-6.321401596069336,-6.316967964172363,-6.325678825378418,-6.315784931182861,-6.317835807800293,-6.318266868591309,-6.316442012786865,-6.328617095947266,-6.32712459564209,-6.31711483001709,-6.325334548950195,-6.3173980712890629,-6.326519012451172,-6.327071666717529,-6.328158855438232,-6.331101417541504,-6.340438365936279,-6.338006019592285,-6.341097831726074,-6.337981224060059,-6.338255882263184,-6.326967716217041,-6.331080436706543,-6.3282060623168949,-6.333209991455078,-6.319314002990723,-6.326709270477295,-6.331586837768555,-6.323542594909668,-6.292738914489746,-6.313663959503174,-6.313014984130859,-6.314057350158691,-6.31964635848999,-6.318821907043457,-6.312053680419922,-6.317728042602539,-6.314077854156494,-6.312402248382568,-6.337514400482178,-6.3323564529418949,-6.323975563049316,-6.328218936920166,-6.333804130554199,-6.323490142822266,-6.324713706970215,-6.318416118621826,-6.3246588706970219,-6.333000183105469,-6.333883762359619,-6.343333721160889,-6.349112510681152,-6.345839023590088,-6.348855972290039,-6.3537397384643559,-6.347458839416504,-6.343589782714844,-6.349026203155518,-6.3388471603393559,-6.3291215896606449,-6.3273773193359379,-6.321824550628662]},{\"name\":\"output__1\",\"datatype\":\"FP32\",\"shape\":[1,384],\"data\":[-6.145981311798096,-6.4137492179870609,-6.179805278778076,-6.348742485046387,-4.50963830947876,-6.294920921325684,-6.433112144470215,-6.220922946929932,-6.464371204376221,-6.550308704376221,-6.271365165710449,-6.087484359741211,-6.254318714141846,-6.0754714012146,-6.086469650268555,-6.180393218994141,-6.2104172706604,-6.078750133514404,-6.313652515411377,-5.868254661560059,-5.645192623138428,-5.46496057510376,-6.049006938934326,-6.333099842071533,-5.989526748657227,-5.897788047790527,-5.232300758361816,-5.2602362632751469,-5.8117451667785648,-6.306882858276367,-5.861926078796387,-5.345408916473389,-4.645256042480469,-5.888984680175781,-6.0972900390625,-6.109769821166992,-5.298713684082031,-6.033993721008301,-6.195100784301758,-6.261682510375977,-2.54917049407959,-2.366212844848633,-0.8876939415931702,-6.181464672088623,-6.131988525390625,-6.10410213470459,-5.497006416320801,-5.947528839111328,-5.986529350280762,-6.221286773681641,-5.998957633972168,-5.859094142913818,-5.938549518585205,-6.182814598083496,-6.221398830413818,-6.020956993103027,-5.895058631896973,-6.120546340942383,-6.099771499633789,-5.7306952476501469,-5.731251239776611,-6.117954254150391,-6.188318252563477,-6.053421974182129,-6.046887397766113,-6.297938346862793,-5.181695461273193,-3.8793137073516847,-6.114604949951172,-6.175142288208008,-6.032340049743652,-6.119104862213135,-6.1510210037231449,-5.42059850692749,-4.744919776916504,-6.002022743225098,-6.150199890136719,-6.087215423583984,-5.775862693786621,-6.2202043533325199,-6.276278018951416,-5.438079833984375,-3.816230535507202,-6.480782985687256,-5.533854007720947,-6.3962178230285648,-6.808626174926758,-5.532477378845215,-5.969341278076172,-6.054061412811279,-4.9035468101501469,-6.519473075866699,-1.4933276176452637,-6.481350421905518,-6.956860542297363,-6.894136905670166,-5.852993488311768,6.382648468017578,-2.364443063735962,-5.8607001304626469,-3.7147140502929689,-6.061554908752441,-6.179474830627441,-6.28945255279541,-6.328498840332031,-6.52185583114624,-5.721749305725098,-6.546082019805908,2.507746458053589,-6.164210319519043,-6.282215118408203,-5.721388339996338,-6.131737232208252,-6.28651237487793,-6.526206016540527,-5.890008926391602,-6.204228401184082,-5.828078269958496,-4.950246810913086,-6.228482246398926,-6.460685729980469,1.597111701965332,-5.462097644805908,-5.093373775482178,-3.9471287727355959,-6.155576229095459,-5.92521858215332,-6.277928352355957,-6.008408546447754,-6.140478134155273,-6.395411968231201,-6.155952453613281,-6.00042724609375,-6.257120609283447,-5.300798416137695,-4.272651672363281,-4.200445175170898,-5.790348052978516,-6.0527849197387699,-6.193262577056885,-6.416034698486328,-5.804675579071045,-6.158040523529053,-6.1749348640441898,-6.027600288391113,-6.066593647003174,-5.818799018859863,-5.614012718200684,-4.021734237670898,-5.957595348358154,-6.063704967498779,-6.2143473625183109,-6.351897239685059,-6.096456527709961,-6.128740310668945,-6.012302875518799,-6.284150123596191,-6.044527053833008,-5.392615795135498,-5.741559982299805,-6.192663669586182,-6.2391462326049809,-6.267463684082031,-6.257460594177246,-5.8637895584106449,-6.421792030334473,-3.8174870014190676,-4.795653343200684,-3.6855077743530275,-4.956202507019043,-6.248690605163574,-6.384306907653809,-5.827315330505371,-5.555244445800781,-6.190595626831055,-5.7934370040893559,-6.139277458190918,-6.24317741394043,-6.231000900268555,-5.957633018493652,-6.224750518798828,-6.03207540512085,-6.265015602111816,-5.388524055480957,-6.328727722167969,-6.063684463500977,-5.987453937530518,-5.4093337059021,-6.060685157775879,-6.129947662353516,-6.191190719604492,-5.733059883117676,-5.710233688354492,-6.086957931518555,-6.313345909118652,-6.0355072021484379,-5.7549004554748539,-5.916807174682617,-5.7285356521606449,-6.21800422668457,-6.429189682006836,-6.194988250732422,-5.928847789764404,-5.552422046661377,-4.122220039367676,-6.100082874298096,-6.169649124145508,-6.162181377410889,-6.1671929359436039,-6.148375511169434,-6.154226303100586,-6.164253234863281,-6.150196075439453,-6.144266128540039,-6.147159576416016,-6.148448944091797,-6.141120910644531,-6.1549072265625,-6.1563825607299809,-6.1552815437316898,-6.161144256591797,-6.158027172088623,-6.156544208526611,-6.157660484313965,-6.161147117614746,-6.1529364585876469,-6.162309169769287,-6.161838531494141,-6.158642768859863,-6.156210422515869,-6.159999370574951,-6.160545349121094,-6.154335021972656,-6.156489372253418,-6.166864395141602,-6.1528520584106449,-6.1303253173828129,-6.14607048034668,-6.21649169921875,-6.163739204406738,-6.171862602233887,-6.16949987411499,-6.165491104125977,-6.168490409851074,-6.168259143829346,-6.157528877258301,-6.166905879974365,-6.1634321212768559,-6.151745796203613,-6.157607078552246,-6.152508735656738,-6.158771991729736,-6.1657209396362309,-6.166537284851074,-6.166207313537598,-6.167341232299805,-6.170803070068359,-6.167038440704346,-6.159346103668213,-6.166566848754883,-6.158592700958252,-6.165042877197266,-6.164324760437012,-6.164675712585449,-6.166018486022949,-6.160394668579102,-6.164621353149414,-6.165574073791504,-6.152146339416504,-6.149662017822266,-6.178012847900391,-6.168910980224609,-6.167173385620117,-6.166412353515625,-6.166877269744873,-6.15628719329834,-6.151063919067383,-6.162243843078613,-6.152896404266357,-6.167417526245117,-6.1656389236450199,-6.168049335479736,-6.1657304763793949,-6.163657188415527,-6.1683855056762699,-6.170191287994385,-6.169010639190674,-6.166071891784668,-6.169839859008789,-6.162440299987793,-6.1670427322387699,-6.165556907653809,-6.158418655395508,-6.166387557983398,-6.157236576080322,-6.1590166091918949,-6.153186798095703,-6.15906286239624,-6.1523895263671879,-6.160091876983643,-6.1556715965271,-6.150586128234863,-6.142427444458008,-6.147610664367676,-6.151123523712158,-6.145608901977539,-6.152530670166016,-6.1441330909729,-6.145634651184082,-6.150561809539795,-6.146164417266846,-6.157872676849365,-6.1491241455078129,-6.165689468383789,-6.158195972442627,-6.179659366607666,-6.1703386306762699,-6.169336318969727,-6.17445182800293,-6.177197456359863,-6.179549217224121,-6.153315544128418,-6.168386459350586,-6.173438549041748,-6.164636611938477,-6.174257755279541,-6.171382904052734,-6.170927047729492,-6.171683311462402,-6.161879062652588,-6.164122581481934,-6.174978256225586,-6.166604995727539,-6.173360824584961,-6.164370059967041,-6.164378643035889,-6.162929058074951,-6.1603546142578129,-6.149817943572998,-6.153512954711914,-6.149806976318359,-6.152382850646973,-6.152953147888184,-6.165127754211426,-6.158477783203125,-6.160192966461182,-6.154911518096924,-6.168614387512207,-6.160083770751953,-6.154033660888672,-6.161441326141357,-6.189695835113525,-6.172064304351807,-6.173092365264893,-6.173048496246338,-6.168837547302246,-6.1683244705200199,-6.1760759353637699,-6.171905517578125,-6.175711631774902,-6.17656135559082,-6.153139591217041,-6.158093452453613,-6.166867256164551,-6.163541793823242,-6.157207489013672,-6.168302536010742,-6.16520881652832,-6.170495510101318,-6.166165351867676,-6.158967971801758,-6.158591270446777,-6.148868560791016,-6.14283561706543,-6.1463775634765629,-6.143098831176758,-6.138342380523682,-6.144290924072266,-6.149785041809082,-6.14329719543457,-6.155139923095703,-6.159875869750977,-6.161025524139404,-6.1684441566467289]}]}')\n"
     ]
    }
   ],
   "source": [
    "results = triton_client.infer(modelName,\n",
    "                                  inputs,\n",
    "                                  outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the <code>results</code> and <code>outputs</code> are of the same data type.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tritonclient.http._requested_output.InferRequestedOutput at 0x7f33145b50f0>,\n",
       " <tritonclient.http._requested_output.InferRequestedOutput at 0x7f33145b49d0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 Post-Processing the Response\n",
    "\n",
    "The results in our case are just logits of start and end positions. Let's process those further to obtain a human readable result. We start by copying the vectors to NumPy to make further processing easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the results by comparing with precomputed values.\n",
    "output0_data = results.as_numpy('output__0')\n",
    "output1_data = results.as_numpy('output__1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the output..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.2304993, -5.988884 , -6.157663 , -6.06822  , -4.5110598,\n",
       "        -6.1771555, -5.9670124, -6.233505 , -5.894256 , -5.6070166,\n",
       "        -6.033555 , -6.302067 , -6.143382 , -6.211335 , -6.3532295,\n",
       "        -6.214389 , -6.0064845, -6.23081  , -5.773906 , -6.385979 ,\n",
       "        -6.442009 , -6.5102725, -6.268529 , -5.816762 , -6.2957683,\n",
       "        -6.293145 , -6.4921436, -6.3164907, -6.4416842, -5.2130537,\n",
       "        -6.26847  , -6.562448 , -6.120388 , -6.3689384, -6.228873 ,\n",
       "        -6.0389414, -5.9520264, -6.278862 , -5.933717 , -6.097395 ,\n",
       "        -0.4255836, -4.250477 , -1.1577065, -6.1508856, -5.9867973,\n",
       "        -6.2784433, -6.035305 , -6.371573 , -6.259742 , -6.109337 ,\n",
       "        -6.069693 , -6.3170094, -6.376259 , -6.140277 , -5.981711 ,\n",
       "        -6.312574 , -6.2149525, -6.25721  , -6.2140055, -6.0792603,\n",
       "        -6.480047 , -6.1744103, -6.160393 , -5.91033  , -6.3136454,\n",
       "        -6.0063744, -5.0427103, -4.8972197, -5.936635 , -5.89367  ,\n",
       "        -6.2945185, -6.1085763, -6.223854 , -4.444372 , -6.541983 ,\n",
       "        -6.334278 , -6.204667 , -6.2306814, -6.329833 , -6.1436806,\n",
       "        -6.0293913, -5.858162 , -4.8805785, -5.457037 , -6.0207567,\n",
       "        -3.5956075, -4.5559998, -4.842551 , -3.905106 , -6.2730284,\n",
       "        -5.7415714, -5.5641346, -1.4180324, -5.5055933, -3.1139514,\n",
       "        -3.6749897, -2.5593624,  6.4445543, -5.9198146, -4.8185306,\n",
       "        -6.0462813, -6.1528406, -6.0823364, -6.0164347, -5.942196 ,\n",
       "        -5.502044 , -6.3030744, -5.6191134,  2.0597463, -6.2096515,\n",
       "        -5.982874 , -6.1831126, -6.16469  , -6.0714283, -5.4232063,\n",
       "        -6.297128 , -5.7436843, -6.275796 , -6.381994 , -6.08648  ,\n",
       "        -5.7580566,  1.3109349, -6.274996 , -6.462141 , -4.9100475,\n",
       "        -6.0462375, -6.352935 , -6.0249934, -6.076229 , -6.187278 ,\n",
       "        -5.765938 , -6.2183204, -6.045366 , -6.116989 , -3.0214787,\n",
       "        -5.8737845, -5.8599825, -6.384911 , -6.0999093, -6.1258903,\n",
       "        -5.774184 , -6.0462775, -6.2096896, -5.9978666, -4.082451 ,\n",
       "        -5.871559 , -6.062483 , -6.079421 , -5.9320397, -6.319857 ,\n",
       "        -6.2835627, -6.1966896, -5.967202 , -6.1826696, -6.131425 ,\n",
       "        -6.271121 , -5.9206266, -6.1833277, -6.2401757, -6.32198  ,\n",
       "        -6.001893 , -5.9923983, -6.0847597, -5.950427 , -5.876703 ,\n",
       "        -5.943562 , -1.6358087, -3.792091 , -5.689519 , -5.9129233,\n",
       "        -6.1754823, -5.813611 , -6.2655153, -6.098993 , -6.220019 ,\n",
       "        -5.8724017, -6.2468576, -6.0342083, -5.9543734, -6.1044674,\n",
       "        -6.197191 , -6.022829 , -6.145919 , -4.24103  , -5.6272335,\n",
       "        -6.227786 , -6.188078 , -6.310754 , -6.299678 , -5.471878 ,\n",
       "        -5.9066544, -6.216003 , -6.238    , -6.272072 , -5.5226974,\n",
       "        -6.1895757, -6.3633156, -6.2728844, -6.1960144, -6.17371  ,\n",
       "        -5.78829  , -6.176262 , -5.979022 , -6.1452813, -4.981307 ,\n",
       "        -6.2029686, -6.32292  , -6.329955 , -6.3254485, -6.343124 ,\n",
       "        -6.3357816, -6.3254695, -6.3416233, -6.34702  , -6.341887 ,\n",
       "        -6.344242 , -6.351983 , -6.337519 , -6.3358164, -6.337243 ,\n",
       "        -6.329118 , -6.332694 , -6.335175 , -6.335345 , -6.331276 ,\n",
       "        -6.3410335, -6.328496 , -6.3309216, -6.3328624, -6.3362465,\n",
       "        -6.3307414, -6.3300486, -6.3345633, -6.333469 , -6.3242254,\n",
       "        -6.3330135, -6.339871 , -6.335682 , -6.2448425, -6.319397 ,\n",
       "        -6.313585 , -6.315464 , -6.3201575, -6.3171973, -6.317914 ,\n",
       "        -6.329793 , -6.32062  , -6.322803 , -6.3358946, -6.330827 ,\n",
       "        -6.3347073, -6.328768 , -6.3228836, -6.321066 , -6.3217373,\n",
       "        -6.320123 , -6.317036 , -6.3211384, -6.3291674, -6.3244176,\n",
       "        -6.3322716, -6.328005 , -6.327324 , -6.3259325, -6.324544 ,\n",
       "        -6.331922 , -6.3270707, -6.3231573, -6.3326   , -6.332138 ,\n",
       "        -6.30896  , -6.318874 , -6.321487 , -6.322027 , -6.323427 ,\n",
       "        -6.335472 , -6.341618 , -6.3295727, -6.338121 , -6.321803 ,\n",
       "        -6.323139 , -6.321608 , -6.3233337, -6.3245087, -6.319707 ,\n",
       "        -6.3167095, -6.3202376, -6.3236   , -6.3191833, -6.3275976,\n",
       "        -6.3247004, -6.326728 , -6.334611 , -6.3272204, -6.334695 ,\n",
       "        -6.333318 , -6.3393173, -6.333972 , -6.3400626, -6.3320026,\n",
       "        -6.33642  , -6.3405995, -6.3494153, -6.345626 , -6.3419847,\n",
       "        -6.347371 , -6.339195 , -6.346607 , -6.3457136, -6.3413353,\n",
       "        -6.3471155, -6.3348475, -6.3415027, -6.3221507, -6.327181 ,\n",
       "        -6.3054647, -6.318156 , -6.317935 , -6.3125725, -6.3101673,\n",
       "        -6.3075104, -6.335878 , -6.3214016, -6.316968 , -6.325679 ,\n",
       "        -6.315785 , -6.317836 , -6.318267 , -6.316442 , -6.328617 ,\n",
       "        -6.3271246, -6.317115 , -6.3253345, -6.317398 , -6.326519 ,\n",
       "        -6.3270717, -6.328159 , -6.3311014, -6.3404384, -6.338006 ,\n",
       "        -6.341098 , -6.337981 , -6.338256 , -6.3269677, -6.3310804,\n",
       "        -6.328206 , -6.33321  , -6.319314 , -6.3267093, -6.331587 ,\n",
       "        -6.3235426, -6.292739 , -6.313664 , -6.313015 , -6.3140574,\n",
       "        -6.3196464, -6.318822 , -6.3120537, -6.317728 , -6.314078 ,\n",
       "        -6.3124022, -6.3375144, -6.3323565, -6.3239756, -6.328219 ,\n",
       "        -6.333804 , -6.32349  , -6.3247137, -6.318416 , -6.324659 ,\n",
       "        -6.333    , -6.333884 , -6.3433337, -6.3491125, -6.345839 ,\n",
       "        -6.348856 , -6.3537397, -6.347459 , -6.34359  , -6.349026 ,\n",
       "        -6.338847 , -6.3291216, -6.3273773, -6.3218246]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output0_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and convert it into a human readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fungi\n",
      "\n",
      "[\n",
      "    {\n",
      "        \"text\": \"fungi\",\n",
      "        \"probability\": 1.0,\n",
      "        \"start_logit\": 6.444554328918457,\n",
      "        \"end_logit\": 6.382648468017578\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "start_logits = output0_data[0].tolist()\n",
    "end_logits = output1_data[0].tolist()\n",
    "\n",
    "answer, answers = parse_answer(doc_tokens, tokens_for_postprocessing, \n",
    "                                 start_logits, end_logits)\n",
    "\n",
    "# print result\n",
    "print()\n",
    "print(answer)\n",
    "print()\n",
    "print(json.dumps(answers, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
